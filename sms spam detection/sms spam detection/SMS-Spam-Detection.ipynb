{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43a7474a-82a9-471a-98df-2a2a6e195fb0",
   "metadata": {},
   "source": [
    "\n",
    "Dataset Information\n",
    "\n",
    "The \"spam\" category encompasses various types of unsolicited messages, including advertisements for products or websites, schemes promising quick financial gains, chain letters, and content related to pornography. The SMS Spam Collection dataset comprises a collection of SMS messages in English, totaling 5,574 messages. These messages have been specifically gathered for research on SMS spam. Each message in the dataset is labeled as either \"ham,\" indicating it is legitimate, or \"spam,\" indicating it is unsolicited or unwanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055e5136-850f-4bd3-96ab-376a0a712ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b8ff17-8b07-4063-a5e2-0b1ed5d11b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\\\Users\\\\MALATHIKA.P\\\\Downloads\\\\spam.csv', encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b680fe3-2b11-4308-ae86-6660b0bf8885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with encoding utf-8 : 'utf-8' codec can't decode bytes in position 135-136: invalid continuation byte\n",
      "File read successfully with encoding: latin1\n",
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "# In order to resolve error while loading dataset, suitable encoding is checked\n",
    "# Try reading with different encodings\n",
    "encodings = ['utf-8', 'latin1', 'ISO-8859-1', 'windows-1252']\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        df = pd.read_csv(r'C:\\\\Users\\\\MALATHIKA.P\\\\Downloads\\\\spam.csv', encoding=encoding)\n",
    "        print(\"File read successfully with encoding:\", encoding)\n",
    "        print(df.head())\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(\"Error with encoding\", encoding, \":\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8181e72c-30d2-45bf-bcf4-cf1e6768a49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages label\n",
       "0  Go until jurong point, crazy.. Available only ...   ham\n",
       "1                      Ok lar... Joking wif u oni...   ham\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
       "3  U dun say so early hor... U c already then say...   ham\n",
       "4  Nah I don't think he goes to usf, he lives aro...   ham"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetching important columns for processing\n",
    "df = df[['v2', 'v1']]\n",
    "df = df.rename(columns={'v2': 'messages', 'v1': 'label'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76265ad9-ecdf-4531-b974-963343b08121",
   "metadata": {},
   "source": [
    "Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f7f8ea-1f6e-416e-92f6-0dea7a58b7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "messages    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f20a178-71af-4740-ac70-ba0fa55ee616",
   "metadata": {},
   "source": [
    "Variables Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dccc10f-c9b0-43cc-805b-8efefca9eb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MALATHIKA.P\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# download stopwords if not already\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d07746a-c447-42c2-ac81-c75ef76214c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    # removing special characters\n",
    "    text = re.sub(r'[^0-9a-zA-Z]', ' ', text)\n",
    "    # removing extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # removing stopwords\n",
    "    text = \" \".join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d139e59a-9d5d-4532-bae7-d8ac85d9e0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>messages</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "      <td>nah think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            messages label  \\\n",
       "0  Go until jurong point, crazy.. Available only ...   ham   \n",
       "1                      Ok lar... Joking wif u oni...   ham   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam   \n",
       "3  U dun say so early hor... U c already then say...   ham   \n",
       "4  Nah I don't think he goes to usf, he lives aro...   ham   \n",
       "\n",
       "                                          clean_text  \n",
       "0  go jurong point crazy available bugis n great ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3                u dun say early hor u c already say  \n",
       "4             nah think goes usf lives around though  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning the messages\n",
    "df['clean_text'] = df['messages'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c28f58-2122-4644-9c88-69adef917fb9",
   "metadata": {},
   "source": [
    "Variables Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36714e6-4510-4ee8-9c5b-c92bbc1c9c5f",
   "metadata": {},
   "source": [
    "X = df['clean_text']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b908331b-030f-4751-b37c-bccf2c150fb5",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b70d646-d526-408d-bdfc-55335dc946c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "def classify(model, X, y):\n",
    "    # train test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=True, stratify=y)\n",
    "    # model training\n",
    "    pipeline_model = Pipeline([('vect', CountVectorizer()),\n",
    "                              ('tfidf', TfidfTransformer()),\n",
    "                              ('clf', model)])\n",
    "    pipeline_model.fit(x_train, y_train)\n",
    "    \n",
    "    print('Accuracy:', pipeline_model.score(x_test, y_test)*100)\n",
    "    \n",
    "#     cv_score = cross_val_score(model, X, y, cv=5)\n",
    "#     print(\"CV Score:\", np.mean(cv_score)*100)\n",
    "    y_pred = pipeline_model.predict(x_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277ca7c6-6246-4ab8-955c-0ddf10692106",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17ce6ff3-42c0-4f8e-9049-5449a7361908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.8413496051687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      1206\n",
      "        spam       0.99      0.77      0.87       187\n",
      "\n",
      "    accuracy                           0.97      1393\n",
      "   macro avg       0.98      0.88      0.92      1393\n",
      "weighted avg       0.97      0.97      0.97      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "classify(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd303c0-5dbc-4d03-88de-24977160e938",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "028612e6-b614-41c0-b42a-0f202dbfa831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.69777458722182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1206\n",
      "        spam       1.00      0.75      0.86       187\n",
      "\n",
      "    accuracy                           0.97      1393\n",
      "   macro avg       0.98      0.88      0.92      1393\n",
      "weighted avg       0.97      0.97      0.96      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "classify(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87124de-b6e3-4ee6-bb72-da81adc92a5c",
   "metadata": {},
   "source": [
    "Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0e99d60-e8bd-44dd-b352-2f18c683213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.27709978463747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      1206\n",
      "        spam       1.00      0.87      0.93       187\n",
      "\n",
      "    accuracy                           0.98      1393\n",
      "   macro avg       0.99      0.94      0.96      1393\n",
      "weighted avg       0.98      0.98      0.98      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(C=3)\n",
    "classify(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedbfb88-ef9d-4161-bdac-897817270f69",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef69027d-2f21-42d2-9a2e-61ce95cfe3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.63101220387652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99      1206\n",
      "        spam       1.00      0.82      0.90       187\n",
      "\n",
      "    accuracy                           0.98      1393\n",
      "   macro avg       0.99      0.91      0.94      1393\n",
      "weighted avg       0.98      0.98      0.98      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "classify(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9109f92-8ed9-4d11-9711-5f70d98740ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
